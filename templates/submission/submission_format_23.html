<p>
    <b>
        The submission will be ranked based on completeness of the trajectory as well as on the position accuracy (ATE).
    </b>
</p>

<h2>Solution</h2>
<p>Upload a .zip file with a list of text files named after the rosbag files.</p>
<p>For Challenge 2022:</p>
<pre><code>BASEMENT_1.txt
IC_OFFICE_1.txt
OFFICE_MITTE_1.txt
....</code></pre>
<p>For Challenge 2023:</p>
<pre><code>site1_handheld_1.txt
site1_handheld_2.txt
site1_handheld_3.txt
....</code></pre>

<p>The text files should have the following content:</p>
<pre><code># timestamp_s tx ty tz qx qy qz qw
1.403636580013555527e+09 0.0 0.0 0.0 0.0 0.0 0.0 0.0
...</code></pre>

<p>
    The file should be space separated. Each line stands for the pose at the specified timestamp. The timestamps are in
    the unit of second and used to establish temporal correspondences with the groundtruth. The first pose should be no
    later than the starting times specified above, and only poses after the starting times will be used for
    evaluation.
</p>
<p>
    The pose is composed of translation (<code>tx</code> <code>ty</code> <code>tz</code>, in meters) and quaternion (in
    Hamilton quaternion, the <code>w</code> component is at the end). The pose should specify the pose of the IMU in the
    world frame. For example, after converting the pose to a transformation matrix <code>Twi</code>, one should be able
    to transform the homogeneous point coordinates in IMU frame to world frame as <code>pw = Twi * pi</code>.
</p>
<p>Do not publish your trajectory estimates, as we might re-use some of the datasets for future competitions.</p>

<p>
    You are welcome to submit your own Lidar-IMU extrinsics if you perform your own
    calibration. We include this option specifically because:
</p>
<ul>
    <li>The robot observes Ground Control Points from the hemisphere Lidar.</li>
    <li>Majority of participant SLAM systems are Lidar driven</li>
    <li>SLAM is evaluated on the IMU reference frame</li>
</ul>

<p>
    To include your own extrinsics, simply include an `extrinsics_robot.yaml` in your .zip file.
    Note that the yaml file reference frames should be in the multical format, identical to what we provide
    to all participants.
</p>

<h2>Report</h2>
<p>
    In addition to the estimated trajectories, the participants are required to submit a short report summarizing their
    approach. The reports of all teams will be published on the website upon submission. The format of the report is
    left to the discretion of the participants, however the report must specify the following information:
</p>
<ul>
    <li>A brief overview of the approach
        <ul>
            <li>Filter or optimization-based (or else)?</li>
            <li>
                Is the method causal? (i.e. does not use information from the future to predict the pose at a given
                time).
            </li>
            <li>Is bundle adjustment (BA) used? What type of BA, e.g. full BA or sliding window BA?</li>
            <li>Is loop closing used?</li>
        </ul>
    </li>
    <li>Exact sensor modalities used (IMU, stereo or mono, LIDAR data?)</li>
    <li>Total processing time for each sequence and the used hardware</li>
    <li>Whether the same set of parameters is used throughout all the sequences</li>
    <li>Whether manual alignment was performed for maps/trajectories in the multi-session submission.</li>
</ul>

<p>
    The participants are welcome to include further details of their approach, potential references to a paper
    describing the approach, or any other additional information.
</p>
